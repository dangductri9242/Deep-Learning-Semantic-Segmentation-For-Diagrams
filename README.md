# Deep-Learning-Semantic-Segmentation-For-Diagrams
This is my Honor Thesis under Dr. Michael Cormier at Mount Allison University. The main task was building deep learning models to learn the features from pictures of diagrams and predict the semantic segmentation of the image.

Abstract:
This thesis is a part of the TADA project, short for “Touch-and-Audio-based Diagram Access for Blind and Low-Vision People”. The TADA project is a tablet-based interactive system designed to make diagram exploration accessible to blind and low-vision (BLV) people through musical tones and speech. In this paper, we are conducting the experiment of producing the semantic segmentation from diagrams using deep learning methodologies, as a part of the TADA project pipeline. The main concept of deep learning that has been used is Convolutional Neural Network (CNN), using a linear neural network and encoder-decoder network. Furthermore, we also experimented with superpixel segmentation, how it performed with CNN and semantic segmentation. Overall, we observed very positive result from our models when performing semantic segmentations. In addition, we also figured that the idea of superpixel was not suitable for the purpose of creating semantic segmentation for diagrams. 
